{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "javascript_functions = {False: \"hide()\", True: \"show()\"}\n",
    "button_descriptions  = {False: \"Show code\", True: \"Hide code\"}\n",
    "\n",
    "\n",
    "def toggle_code(state):\n",
    "\n",
    "    \"\"\"\n",
    "    Toggles the JavaScript show()/hide() function on the div.input element.\n",
    "    \"\"\"\n",
    "\n",
    "    output_string = \"<script>$(\\\"div.input\\\").{}</script>\"\n",
    "    output_args   = (javascript_functions[state],)\n",
    "    output        = output_string.format(*output_args)\n",
    "\n",
    "    display(HTML(output))\n",
    "\n",
    "\n",
    "def button_action(value):\n",
    "\n",
    "    \"\"\"\n",
    "    Calls the toggle_code function and updates the button description.\n",
    "    \"\"\"\n",
    "\n",
    "    state = value.new\n",
    "\n",
    "    toggle_code(state)\n",
    "\n",
    "    value.owner.description = button_descriptions[state]\n",
    "\n",
    "\n",
    "state = False\n",
    "toggle_code(state)\n",
    "\n",
    "button = widgets.ToggleButton(state, description = button_descriptions[state])\n",
    "button.observe(button_action, \"value\")\n",
    "\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.special import expit\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings (\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72200c22",
   "metadata": {},
   "source": [
    "# Parte I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee66a3",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba20e2",
   "metadata": {},
   "source": [
    "Luego de explorar el diseño de registro de la base de hogar, creemos que las siguiens variables puedenn ser muy predictivas de pobreza:\n",
    "\n",
    "IV11 = El desague del baño es:\n",
    "\n",
    "                  1. a red pública (cloaca)\n",
    "                  2. a cámara séptica y pozo ciego \n",
    "                  3. solo a pozo ciego \n",
    "                  4. a hoyo/excavación en la tierra\n",
    "                  \n",
    "IV12_3 = La vivienda está ubicada en villa de emergencia (por observación)\n",
    "\n",
    "                  1 = Sí\n",
    "                  2 = No\n",
    "\n",
    "II7 = Régimen de tenencia: \n",
    "\n",
    "               01 = Propietario de la vivienda y el terreno\n",
    "               02 = Propietario de la vivienda solamente\n",
    "               03 = Inquilino / arrendatario de la vivienda\n",
    "               04 = Ocupante por pago de impuestos / expensas\n",
    "               05 = Ocupante en relación de dependencia\n",
    "               06 = Ocupante gratuito (con permiso)\n",
    "               07 = Ocupante de hecho (sin permiso)\n",
    "               08 = Está en sucesión\n",
    "\n",
    "II8 = Combustible utilizado para cocinar:\n",
    "\n",
    "                 01 = Gas de red\n",
    "                 02 = Gas de tubo / garrafa\n",
    "                 03 = Kerosene / leña / carbón\n",
    "\n",
    "II9 = Baño (tenencia y uso): \n",
    "   \n",
    "        01 = Uso exclusivo del hogar\n",
    "        02 = Compartido con otro/s hogar/es de la misma vivienda\n",
    "        03 = Compartido con otra/s vivienda/s\n",
    "        04 = No tiene baño\n",
    "        \n",
    "V5 = ¿En los últimos tres meses, las personas de este hogar han vivido de subsidio o ayuda social (en dinero)del gobierno, iglesias, etc.?: \n",
    "\n",
    "                  1 = Sí\n",
    "                  2 = No\n",
    "\n",
    "V17 = ¿En los últimos tres meses, han tenido que vender alguna de sus pertenencias?:\n",
    "\n",
    "                  1 = Sí\n",
    "                  2 = No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf554d",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b33698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el excel de la EPH\n",
    "eph_hogar = pd.read_excel(\"usu_hogar_T121.xlsx\")\n",
    "eph_indiv = pd.read_excel(\"usu_individual_T121.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2141f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con los aglomerados de CABA y GBA\n",
    "eph_hogar.drop(eph_hogar[(eph_hogar['AGLOMERADO'] != 32) & (eph_hogar[\"AGLOMERADO\"] != 33)].index, inplace = True)\n",
    "eph_hogar.reset_index(inplace = True, drop = True)\n",
    "eph_indiv.drop(eph_indiv[(eph_indiv['AGLOMERADO'] != 32) & (eph_indiv[\"AGLOMERADO\"] != 33)].index, inplace = True)\n",
    "eph_indiv.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1255aef1",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junto la eph de hogares y individuos por la columna CODUSU, el suffixes = (\"\", \"_y\") es para que distinga las columnas\n",
    "#repetidas en ambos dataframes colocandolo el sufijo \"y\" a los nombres de las columnas de la eph_indiv\n",
    "eph = eph_hogar.merge(eph_indiv, on = \"CODUSU\", suffixes = (\"\", \"_y\") , how = \"outer\")\n",
    "eph = eph[eph.columns.drop(list(eph.filter(regex='_y')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192decea",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> (Rodrigo) Aquí se debería unir por \"CODUSU\" y \"NRO_HOGAR\", ya que ambos definen un hogar; \"CODUSU\" sólo define una vivienda, que puede contener muchos hogares. Sin embargo, la diferencia es mínima ya que por hacerlo así sólo pierden 9 observaciones, así que la influencia en los resultados que obtienen debería ser despreciable.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f067ea",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b75f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_eph(eph):\n",
    "\n",
    "    '''\n",
    "        función para limpiar la eph\n",
    "        input:\n",
    "            eph: Variable que tenga almacenada la eph sin limpiar\n",
    "\n",
    "        output:\n",
    "            eph: Variable que tiene almacenada la eph limpia\n",
    "    '''\n",
    "    \n",
    "    eph.dropna(thresh = 1, inplace = True) # Si tiene todos NA, la fila se va\n",
    "    \n",
    "    eph.dropna(thresh = 1, axis = \"columns\", inplace = True) # Si la columna tiene todos NA, la columna se va\n",
    "    \n",
    "    try:\n",
    "        # Si no lo defino como uno me dropea un montón de filas que tienen NaN\n",
    "        eph.PP08D1 = eph.PP08D1.fillna(0)\n",
    "        eph.PP08F2 = eph.PP08F2.fillna(0)\n",
    "        # dropeo observaciones con valores que no tienen sentido. CH06 = edad, PP08D1, P21, P47T, ITF y IPCF son \n",
    "        # todas variables de ingresos, no pueden ser menores a 0\n",
    "        eph.drop(eph[(eph[\"CH06\"] < 0) | (eph[\"PP08D1\"] < 0) | (eph[\"P21\"] < 0) | \n",
    "                     (eph[\"P47T\"] < 0) | (eph[\"ITF\"] < 0) | (eph[\"IPCF\"] < 0) | \n",
    "                     (eph[\"PP08F2\"] < 0)].index, inplace = True)\n",
    "        eph[\"CH14\"].fillna(99, inplace = True) #Muchos no respondieron entonces reemplazamos los missing por 99.\n",
    "        eph.fillna(0, inplace = True) # Relleno todos con 0 los missing de las columnas que representan subcategorías en\n",
    "        #las que solo respondieron algunos. \n",
    "        #Para las siguientes variables dummys hay entre 15 y 20 observaciones para las que toma valor 9, es decir Ns/Nr.\n",
    "        #Como son pocas observaciones y siempre las mismas, optamos por eliminarlas. \n",
    "        eph.drop(eph[(eph[\"V1\"] == 9 ) | (eph[\"V2\"] == 9) | (eph[\"V3\"] == 9) | (eph[\"V4\"] == 9) | (eph[\"V5\"] == 9) | \n",
    "                     (eph[\"V6\"] == 9 ) | (eph[\"V7\"] == 9) | (eph[\"V8\"] == 9) | (eph[\"V9\"] == 9) | (eph[\"V10\"] == 9) | \n",
    "                     (eph[\"V11\"] == 9) | (eph[\"V12\"] == 9) | (eph[\"V13\"] == 9) | (eph[\"V14\"] == 9) | (eph[\"V15\"] == 9) |\n",
    "                     (eph[\"V16\"] == 9) | (eph[\"V17\"] == 9) | (eph[\"V18\"] == 9) | (eph[\"V19_A\"] == 9) | \n",
    "                     (eph[\"V19_B\"] == 9)].index, inplace = True)\n",
    "        eph.reset_index(inplace = True, drop = True)  \n",
    "    except:\n",
    "        print(\"No se encontró alguna columna, revisar\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7163964b",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e4839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "limpiar_eph(eph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13703973",
   "metadata": {},
   "source": [
    "## 6 (hay que correr el codigo hasta el punto 9 iclusive antes de correr el codigo de este punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a21371",
   "metadata": {},
   "source": [
    "Las variables a analizar son 5 de las mencionadas en el punto 1: \n",
    "    \n",
    "    IV12_3, II8, V5, V17 y II9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IV12_3 = La vivienda está ubicada en villa de emergencia (por observación)\n",
    "eph[\"IV12_3\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobres_villa = proporción de pobres que viven en villas de emergencia. \n",
    "# pobres_no_villa = proporción de pobres que no viven en villas de emergencia.\n",
    "pobres_villa = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"IV12_3\"] == 1)].IV12_3.apply(\"count\")\n",
    "pobres_no_villa = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"IV12_3\"] == 2)].IV12_3.apply(\"count\")\n",
    "pobres_villa = pobres_villa/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "pobres_no_villa = pobres_no_villa/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "# villa = proporción de no pobres que viven en villas de emergencia. \n",
    "# no_villa = proporción de no pobres que no viven en villas de emergencia.\n",
    "villa = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"IV12_3\"] == 1)].IV12_3.apply(\"count\")\n",
    "no_villa = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"IV12_3\"] == 2)].IV12_3.apply(\"count\")\n",
    "villa = villa/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "no_villa = no_villa/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "# Gráfico de barras que compara la proporción de pobres y no pobres que viven en villas de emergencia.\n",
    "plt.bar(\"pobres\", pobres_villa)\n",
    "plt.bar(\"no pobres\", villa)\n",
    "plt.title(\"% de personas en villas de emergencia\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff956ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eph[\"II8\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c562d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobres_gas_tubo = proporción de pobres que utilizan gas de tubo. \n",
    "# pobres_gas_red = proporción de pobres que utilizan gas de red.\n",
    "pobres_gas_tubo = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"II8\"] == 2)].II8.apply(\"count\")\n",
    "pobres_gas_red = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"II8\"] == 1)].II8.apply(\"count\")\n",
    "pobres_gas_tubo = pobres_gas_tubo/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "pobres_gas_red = pobres_gas_red/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "# gas_tubo = proporción de no pobres que que utilizan gas de tubo.\n",
    "# gas_red = proporción de no pobres que que utilizan gas de red.\n",
    "gas_tubo = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"II8\"] == 2)].II8.apply(\"count\")\n",
    "gas_red = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"II8\"] == 1)].II8.apply(\"count\")\n",
    "gas_tubo = gas_tubo/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "gas_red = gas_red/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "# Gráfico de barras que compara la proporción de pobres y no pobres que usan garrafa.\n",
    "plt.bar(\"pobres\", pobres_gas_tubo)\n",
    "plt.bar(\"no pobres\", gas_tubo)\n",
    "plt.title(\"% de personas que usan garrafa\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0481ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eph[\"V5\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1502f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobres_plan = proporción de pobres que recibieron subsidio o ayuda social en los últimos 3 meses. \n",
    "pobres_plan = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"V5\"] == 2)].V5.apply(\"count\")\n",
    "pobres_plan = pobres_plan/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "# plan = proporción de no pobres que recibieron subsidio o ayuda social en los últimos 3 meses.\n",
    "plan = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"V5\"] == 2)].V5.apply(\"count\")\n",
    "plan = plan/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "# Gráfico de barras que compara la proporción de pobres y no pobres que recibieron planes o ayuda social.\n",
    "plt.bar(\"pobres\", pobres_plan)\n",
    "plt.bar(\"no pobres\", plan)\n",
    "plt.title(\"% de personas que recibieron planes recientemente\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "eph[\"V17\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobres_venta = proporción de pobres que tuvieron que vender pertenencias en los últimos 3 meses. \n",
    "pobres_venta = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"V17\"] == 1)].V17.apply(\"count\")\n",
    "pobres_venta = pobres_venta/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "# venta = proporción de no pobres que tuvieron que vender pertenencias en los últimos 3 meses.\n",
    "venta = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"V17\"] == 1)].V17.apply(\"count\")\n",
    "venta = venta/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "# Gráfico de barras que compara la proporción de pobres y no pobres que tuvieron que vender pertenencias en los últimos 3 meses.\n",
    "plt.bar(\"pobres\", pobres_venta)\n",
    "plt.bar(\"no pobres\", venta)\n",
    "plt.title(\"% de personas que vendieron pertenencias\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e10d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "eph[\"II9\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393bbcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pobres_menor = proporción de pobres que no tienen baños exclusivos.\n",
    "pobres_baño_vulnerable = respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"II9\"] == 2)].II9.apply(\"count\")\n",
    "pobres_baño_vulnerable += respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"II9\"] == 3)].II9.apply(\"count\")\n",
    "pobres_baño_vulnerable += respondieron[(respondieron[\"pobre\"] == 1) & (respondieron[\"II9\"] == 4)].II9.apply(\"count\")\n",
    "pobres_baño_vulnerable = pobres_baño_vulnerable/(respondieron[respondieron[\"pobre\"] == 1].pobre.apply(\"count\"))\n",
    "# menor = proporción de no pobres que no tienen baños exclusivos.\n",
    "baño_vulnerable = respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"II9\"] == 2)].II9.apply(\"count\")\n",
    "baño_vulnerable += respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"II9\"] == 3)].II9.apply(\"count\")\n",
    "baño_vulnerable += respondieron[(respondieron[\"pobre\"] == 0) & (respondieron[\"II9\"] == 4)].II9.apply(\"count\")\n",
    "baño_vulnerable = baño_vulnerable/(respondieron[respondieron[\"pobre\"] == 0].pobre.apply(\"count\"))\n",
    "# Gráfico de barras que compara la proporción de pobres y no pobres que no tienen baños exclusivos.\n",
    "plt.bar(\"pobres\", pobres_baño_vulnerable)\n",
    "plt.bar(\"no pobres\", 0.0001)\n",
    "plt.title(\"% de personas sin baño exclusivo\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f02753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una matriz de correlaciones de las variables descriptas\n",
    "correlaciones = respondieron[[\"IV12_3\", \"II8\", \"V5\", \"V17\", \"II9\", \"pobre\"]].corr()\n",
    "#Realizamos la matriz de correlaciones \n",
    "sns.heatmap(correlaciones, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62f8e2",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> (Rodrigo) Para variables categóricas como las elegidas no es muy informativo reportar cantidades como la media o la desviación estándar. Tiene más sentido reportar la cantidad o proporción de cada categoría (e idealmente el significado de cada código asociado), por ejemplo usando el método `value_counts` de Pandas. respondió a esa pregunta.\n",
    "</span> <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c152c",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63098145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la tabla de excel\n",
    "tabla_adulto = pd.read_excel(\"tabla_adulto_equiv.xlsx\", header = 3)\n",
    "#Ajustamos el formato de la tabla \n",
    "tabla_adulto.dropna(axis = 1, inplace = True, thresh = 10)\n",
    "tabla_adulto.dropna(inplace = True, thresh = 3)\n",
    "tabla_adulto.reset_index(inplace = True, drop = True)\n",
    "#Creamos la columna \"adulto_equiv\" como una columna de ceros\n",
    "eph[\"adulto_equiv\"] = 0\n",
    "#Generamos una nueva columna llamada lista como una columna de ceros \n",
    "eph[\"lista\"] = 0\n",
    "#Iteramos por filas\n",
    "#Para cada fila del data frame de acuerdo a la edad le indicamos que \n",
    "#la celda de la columna \"lista\" la complete con el número correspondiente \n",
    "#al índice de la tabla_adulto. \n",
    "#Por ejemplo, si la edad es menor a 30 entonces se asigna el numero 18 que es\n",
    "#el índice de la fila de 18 a 29 años. \n",
    "for i in eph.index:\n",
    "    if eph.loc[i, \"CH06\"] < 19:\n",
    "        eph.loc[i, \"lista\"] = eph.loc[i, \"CH06\"]\n",
    "    elif eph.loc[i, \"CH06\"] < 30:\n",
    "        eph.loc[i, \"lista\"] = 18\n",
    "    elif eph.loc[i, \"CH06\"] < 46:\n",
    "        eph.loc[i, \"lista\"] = 19\n",
    "    elif eph.loc[i, \"CH06\"] < 61:\n",
    "        eph.loc[i, \"lista\"] = 20\n",
    "    elif eph.loc[i, \"CH06\"] < 76:\n",
    "        eph.loc[i, \"lista\"] = 21\n",
    "    else:\n",
    "        eph.loc[i, \"lista\"] = 22\n",
    "#CH06 = edad, CH04 = Sexo (1 = varon y 2 = mujer)\n",
    "#Para cada fila del dataframe si el individuo es varón entonces le indicamos que bajo \n",
    "#la columna \"adulto_equiv\" coloque la siguiente celda de tabla_adulto: \n",
    "# Fila: el índice que esta guardado en la columna \"lista\" en el df eph. \n",
    "# Columna: Varones \n",
    "#idem para las mujeres\n",
    "#De este modo se obtienenn los valores de adulto equivalente de cada persona según \n",
    "#su sexo y edad\n",
    "for i in eph.index:\n",
    "    if eph.loc[i, \"CH04\"] == 1:\n",
    "        eph.loc[i, \"adulto_equiv\"] = tabla_adulto.loc[eph.loc[i, \"lista\"], \"Varones\"]\n",
    "    elif eph.loc[i, \"CH04\"] == 2:\n",
    "        eph.loc[i, \"adulto_equiv\"] = tabla_adulto.loc[eph.loc[i, \"lista\"], \"Mujeres\"]\n",
    "#Eliminamos la columna \"lista\"\n",
    "eph.drop(\"lista\", axis = 1, inplace = True)\n",
    "#Realizamos un groupby: para cada hogar sumamos \"adulto_equiv\"\n",
    "ad_equiv_hogar = eph[[\"CODUSU\", \"adulto_equiv\"]].groupby(\"CODUSU\").sum()\n",
    "ad_equiv_hogar.reset_index(inplace = True)\n",
    "#cambiamos los nombres de las columnas\n",
    "ad_equiv_hogar.columns = [\"CODUSU\", \"ad_equiv_hogar\"]\n",
    "#agregamos la columnna \"ad_equiv_hogar\" al df eph\n",
    "eph = eph.merge(ad_equiv_hogar, on = \"CODUSU\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1f6da",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos la muestra de la EPH en gente que no respondio ingresos totales familiares (ITF) y los que sí.\n",
    "norespondieron = eph[eph[\"ITF\"] == 0]\n",
    "norespondieron.reset_index(inplace = True, drop = True)\n",
    "respondieron = eph[eph[\"ITF\"] != 0]\n",
    "respondieron.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le agregamos la columna ingreso_necesario que nos indica según el hogar, cuánto debe ganar para no ser\n",
    "# considerado pobre\n",
    "ingreso_adulto_min = 18914\n",
    "respondieron[\"ingreso_necesario\"] = ingreso_adulto_min * respondieron[\"ad_equiv_hogar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722c8ed",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f676ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una columna dummy, que dice si el individuo es pobre o no. Depende de si sus ingresos\n",
    "# son mayores a ingreso_necesario\n",
    "respondieron[\"pobre\"] = (respondieron[\"ITF\"] < respondieron[\"ingreso_necesario\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9558cd",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agarramos solo GBA, porque pide calcularlo para GBA\n",
    "eph_gba = respondieron[respondieron[\"AGLOMERADO\"] == 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamos por hogar con el groupby(\"CODUSU\") y nos quedamos con el PONDIH, y la columna de pobre,\n",
    "#para las cuales calculamos la media\n",
    "eph_gba = eph_gba.groupby(\"CODUSU\").agg({\"PONDIH\":\"mean\",\"pobre\":\"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b26d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Armamos la suma de los PONDIH para pobres y para todos\n",
    "pondih_pobres = eph_gba[eph_gba[\"pobre\"] == 1].apply({\"PONDIH\":\"sum\"})\n",
    "pondih_total = eph_gba.apply({\"PONDIH\":\"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46320424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último, los dividimos para así obtener la tasa de hogares pobres\n",
    "pondih_pobres/pondih_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66ca5d",
   "metadata": {},
   "source": [
    "Por lo tanto, la tasa de hogares bajo la liea de pobreza para el GBA es del 36,5%. Por su parte, para el periodo que estamos analizando el Indec reporta que el porcentaje de hogares por debajo de la línea de pobreza (LP) alcanzó el 31,2%; en los cuales reside el 40,6% de las personas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7063cc6",
   "metadata": {},
   "source": [
    "# Parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc47fa",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ceeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_metodo(X_train, X_test, y_train, y_test, modelo, parametro=1.0, n=5):\n",
    "    '''\n",
    "    Función que reporta métricas de evaluación de un modelo a elección.\n",
    "    \n",
    "    input:\n",
    "        X_train: X de entrenamiento.\n",
    "        X_test: X de evaluación.\n",
    "        y_train: Y de entrenamiento.\n",
    "        y_test: Y de evaluación.\n",
    "        modelo: Elección de modelo, default = Logit. (Logit = \"Logit\", Lineal = \"Lineal\", KNN = \"KNN\", Lasso = \"Lasso\",\n",
    "                                                      Ridge = \"Ridge\", Elastic net = \"ElasticNet\", CART = \"CART\", \n",
    "                                                      SVM = \"SVM\", Bagging = \"Bagging\", Random Forest = \"RandomForest\", \n",
    "                                                      Boosting = Boosting\").\n",
    "        parametro: Parámetro de regularización de los modelos. Por default = 1.0\n",
    "        n: Parámetro para definir la catnidad de n-neighbours en KNN. Por default = 5.\n",
    "        \n",
    "    output:\n",
    "        Df con las columnas: (modelo, ecm, parámetro, accuracy, matriz_confusion, auc)\n",
    "        coe: En el caso de un modelo \"Lasso\", se define una variable global con los coeficientes de las variables X.\n",
    "        \n",
    "    '''\n",
    "    global coe\n",
    "    global coef2\n",
    "    ev_modelo = pd.DataFrame(columns=[\"modelo\", \"ecm\", \"parámetro\", \"auc\", \"accuracy\", \"fpr\", \"tpr\"])\n",
    "    \n",
    "    # Filtro para distintos modelos.\n",
    "    pob = LogisticRegression(max_iter = 5000, fit_intercept = False)\n",
    "    if modelo == \"Lineal\":\n",
    "        pob = LinearDiscriminantAnalysis()\n",
    "    elif modelo == \"KNN\":\n",
    "        pob = KNeighborsClassifier(n_neighbors = int(n))\n",
    "    elif modelo == \"Logit\":\n",
    "        pob = LogisticRegression(max_iter = 5000, fit_intercept = False)\n",
    "    elif modelo == \"Lasso\":\n",
    "        pob = LogisticRegression(penalty = \"l1\", max_iter = 5000, \n",
    "                                 fit_intercept = False, solver = \"liblinear\", C = parametro)\n",
    "    elif modelo == \"Ridge\":\n",
    "        pob = LogisticRegression(penalty = \"l2\", max_iter = 5000, \n",
    "                                 fit_intercept = False, solver = \"liblinear\", C = parametro)\n",
    "    elif modelo == \"ElasticNet\":\n",
    "        pob = LogisticRegression(penalty = \"elasticnet\", max_iter = 5000, \n",
    "                                 fit_intercept = False, solver = \"saga\", C = parametro)\n",
    "    elif modelo == \"CART\":\n",
    "        pob = DecisionTreeClassifier(ccp_alpha = parametro)\n",
    "    elif modelo == \"SVM\":\n",
    "        pob = SVC(C = parametro,gamma='auto')\n",
    "    elif modelo == \"Bagging\":\n",
    "        pob = BaggingClassifier(base_estimator=SVC(C = parametro))\n",
    "    elif modelo == \"RandomForest\":\n",
    "        pob = RandomForestClassifier(ccp_alpha = parametro)\n",
    "    elif modelo == \"Boosting\":\n",
    "        pob = GradientBoostingClassifier(learning_rate=1.0, ccp_alpha = parametro)\n",
    "    \n",
    "    # Ajustamos el modelo        \n",
    "    pob = pob.fit(X_train, y_train)     \n",
    "    \n",
    "    # Luego predecimos y con las X de evaluación.\n",
    "    y_pred = pob.predict(X_test)\n",
    "    \n",
    "    if modelo != \"SVM\":\n",
    "        # Probabilidad de que Y tome valor 1 segun el valor de X \n",
    "        y_pred_proba = pob.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #Valores de Accuracy\n",
    "    accuracy_pob = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    #Matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    if modelo != \"SVM\":\n",
    "        #Valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "    if modelo != \"SVM\":\n",
    "        #Curva ROC\n",
    "        display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='Reg_log')\n",
    "        def ROC(roc):\n",
    "            display.plot()  \n",
    "            plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "            plt.show()\n",
    "        ROC(display)\n",
    "\n",
    "    # Error cuadrático medio\n",
    "        \n",
    "    ecm = mean_squared_error(y_pred, y_test)\n",
    "    \n",
    "    if modelo != \"SVM\":\n",
    "        ev_modelo = ev_modelo.append({\"modelo\": modelo, \"ecm\": ecm, \n",
    "                                      \"parámetro\":parametro, \"auc\":auc,\n",
    "                                      \"accuracy\":accuracy_pob, \"fpr\":fpr, \"tpr\":tpr}, ignore_index=True)\n",
    "    elif modelo == \"SVM\":\n",
    "        ev_modelo = ev_modelo.append({\"modelo\": modelo, \"ecm\": ecm, \n",
    "                                      \"parámetro\":parametro,\n",
    "                                      \"accuracy\":accuracy_pob}, ignore_index=True)\n",
    "    if modelo == \"Lasso\":\n",
    "        coe = pob.coef_\n",
    "        coef2 = pd.DataFrame(coef, index=X_test.columns)\n",
    "    \n",
    "    return ev_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43b063",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> (Rodrigo) Esta función debería hacerse lo más genérica posible. Notar que el código para ajustar un modelo es el mismo en esencia. Podemos recibir como argumento un modelo genérico, utilizar el método fit para ajustarlo, y calcular las métricas de interés de la misma manera sin importar de qué modelo se trate. Es decir que no es necesario utilizar sentencias condicionales para particularizar para cada modelo.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194d42d",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df65fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(x, y, k, modelo, parametro=1.0):\n",
    "    '''\n",
    "    Función que realiza validación cruzada con k iteraciones para cierto modelo.\n",
    "    \n",
    "    input:\n",
    "        x: Variables explicativas.\n",
    "        y: Variable dependiente.\n",
    "        k: Cantidad de particiones de los datos.\n",
    "        modelo: Elección de modelo, default = Logit. (Logit = \"Logit\", Lineal = \"Lineal\", KNN = \"KNN\", Lasso = \"Lasso\",\n",
    "                                                      Ridge = \"Ridge\", Elastic net = \"ElasticNet\", CART = \"CART\", \n",
    "                                                      SVM = \"SVM\", Bagging = \"Bagging\", Random Forest = \"RandomForest\", \n",
    "                                                      Boosting = Boosting\").\n",
    "        parametro: Parámetro de regularización de los modelos. Por default = 1.0\n",
    "        n: Parámetro para definir la catnidad de n-neighbours en KNN. Por default = 5.\n",
    "        \n",
    "    output:\n",
    "        Df con las columnas: (modelo, particion, ecm, accuracy, matriz_confusion, auc, fpr, tpr)\n",
    "        coe_cv: En el caso de un modelo \"Lasso\", se define un df global con los coeficientes de las variables X para las \n",
    "                k particiones por CV.\n",
    "    '''\n",
    "    global coe_cv\n",
    "    \n",
    "    if modelo == \"Lasso\":\n",
    "        coe_cv = pd.DataFrame(columns=[\"parámetro\",\"coeficientes\"])\n",
    "    \n",
    "    # Creo el df ecms\n",
    "    ecms = pd.DataFrame(columns=[\"modelo\", \"particion\", \"ecm\", \"parámetro\", \"auc\", \"accuracy\", \"fpr\", \"tpr\"])\n",
    "    \n",
    "    kf = KFold(n_splits = k, shuffle = True)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        x_train, x_test = x.iloc[list(train_index)], x.iloc[list(test_index)]\n",
    "        y_train, y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "        \n",
    "        ev_modelo = evalua_metodo(x_train, x_test, y_train, y_test, modelo, parametro)\n",
    "        \n",
    "        ecms = ecms.append({\"modelo\":ev_modelo[\"modelo\"].item(), \n",
    "                            \"particion\": i, \"ecm\":ev_modelo[\"ecm\"].item(), \n",
    "                            \"parámetro\":parametro, \"auc\":ev_modelo[\"auc\"].item(),\n",
    "                            \"accuracy\":ev_modelo[\"accuracy\"].item(), \"fpr\":ev_modelo[\"fpr\"].item(),\n",
    "                            \"tpr\":ev_modelo[\"tpr\"].item()}, ignore_index=True)\n",
    "        \n",
    "        if modelo == \"Lasso\":\n",
    "            coe_cv = coe_cv.append({\"particion\":i,\"parámetro\":parametro,\"coeficientes\":coe}, ignore_index=True)\n",
    "\n",
    "        ecms = ecms.astype({\"particion\":int})\n",
    "        \n",
    "    return ecms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f938736",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a602bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_config(lista_parametros, x, y, k, modelo):\n",
    "    '''\n",
    "    Función que selecciona los hiperparámetros que menor ECM generen, mediante Cross-Validation.\n",
    "    \n",
    "    input:\n",
    "        lista_parametros: lista de parámetros de regularización de los modelos que se van a usar para evaluar.\n",
    "        x: Variables explicativas.\n",
    "        y: Variable dependiente.\n",
    "        k: Cantidad de particiones de los datos.\n",
    "        modelo: Elección de modelo, default = Logit. (Logit = \"Logit\", Lineal = \"Lineal\", KNN = \"KNN\", Lasso = \"Lasso\",\n",
    "                                                      Ridge = \"Ridge\", Elastic net = \"ElasticNet\", CART = \"CART\", \n",
    "                                                      SVM = \"SVM\", Bagging = \"Bagging\", Random Forest = \"RandomForest\", \n",
    "                                                      Boosting = Boosting\").\n",
    "\n",
    "    output:\n",
    "        todos: df que contiene la información del modelo utilizado con las columnas\n",
    "               (modelo, particion, ecm, parámetro, accuracy, auc, fpr, tpr).\n",
    "        ecms_avg: df que hace el promedio por parámetro, con las columnas \n",
    "                  (modelo, particion, ecm, parámetro, accuracy, auc, fpr, tpr)\n",
    "        ev_modelo: df que contiene la información del mejor modelo elegido por ECM, con las columnas \n",
    "                  (modelo, particion, ecm, parámetro, accuracy, auc, fpr, tpr)\n",
    "        coe_cvs: En el caso de un modelo \"Lasso\", se define un df global con los coeficientes de las variables X para las \n",
    "                k particiones por CV.\n",
    "    '''\n",
    "    global coe_cvs\n",
    "    \n",
    "    # Defino data frames para usar después\n",
    "    \n",
    "    todos = pd.DataFrame(columns=[\"modelo\", \"particion\", \"ecm\", \"parámetro\", \"auc\", \"accuracy\", \"fpr\", \"tpr\"])\n",
    "    if modelo == \"Lasso\":\n",
    "        coe_cvs = pd.DataFrame(columns=[\"parámetro\",\"coeficientes\"])\n",
    "    \n",
    "    # For loop que para cada parámetro corre Cross validation con k particiones.\n",
    "    for i in lista_parametros:\n",
    "        ecms = cross_validation(x, y, k, modelo, i)\n",
    "        # ecmss es un df que guarda los resultados de todos los parámetros k veces.\n",
    "        todos = todos.append(ecms)\n",
    "        if modelo == \"Lasso\":\n",
    "            coe_cvs = coe_cvs.append(coe_cv)\n",
    "    \n",
    "    # ecms_avg es un df que guarda los resultados de todos los parámetros haciendo un promedio de todos los ECM de ecmss\n",
    "    ecms_avg = todos.groupby(\"parámetro\").agg({\"ecm\":\"mean\", \"modelo\":\"max\", \"auc\":\"mean\",\n",
    "                                               \"accuracy\":\"mean\"}).reset_index()\n",
    "    \n",
    "    min_ecm = np.Inf\n",
    "    mejor_parametro = None\n",
    "    # For loop que permite determinar el parámetro que tiene el menor ECM en promedio.\n",
    "    for index, row in ecms_avg.iterrows():\n",
    "        if row[\"ecm\"] < min_ecm:\n",
    "            min_ecm = row[\"ecm\"]\n",
    "            mejor_parametro = float(row[\"parámetro\"])\n",
    "    print(\"El minimo error es \", min_ecm, \" y se da con un parametro de \", mejor_parametro)\n",
    "    \n",
    "    # Corro el modelo con el parámetro seleccionado con menor ECM en promedio.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "    ev_modelo = evalua_metodo(X_train, X_test, y_train, y_test, modelo, mejor_parametro)\n",
    "    \n",
    "    return (todos, ecms_avg, ev_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba871c",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> (Rodrigo) Para esta función, la idea era que reciba una lista de configuraciones de hiperparámetros, donde las configuraciones debían adaptarse a distintos modelos (y los hiperparámetros podían ser más de uno). <br><br>\n",
    "Una forma de hacerlo es hacer que la función reciba además el modelo sin inicializar, es decir el nombre del modelo sin paréntesis, como se hizo en la tutorial 7, por ejemplo `LogisticRegression` <br>\n",
    "Entonces, se iteraría con un `for` sobre los distintos diccionarios de configuraciones y antes de cada llamada a `cross_validation` o `evalua_metodo` se inicializaría el modelo con los hiperparámetros particulares de esa iteración. Sería algo así:\n",
    "```    \n",
    "# este es un ejemplo, pero en realidad configs se debe definir \n",
    "# por fuera de evalua_config (en particular, en evalua_multiples_metodos) \n",
    "# y evalua_config debe recibir algo similar a configs como argumento.\n",
    "\n",
    "configs = [{ \"penalty\": \"l1\", \"C\"=0.1 }, { \"penalty\": \"l2\", \"C\"=0.001 }]\n",
    "\n",
    "for config in configs:\n",
    "    modelo = LogisticRegression\n",
    "    modelo = modelo(**configuracion) # inicializamos el modelo con los hiperparámetros\n",
    "    ..., ..., ... = cross_validation(modelo, ...) # le paso a cross_validation el modelo inicializado\n",
    "```\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86fef2",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21774b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_multiples_metodos(lista_parametros, x, y, k):\n",
    "    '''\n",
    "    Función que corre múltiples métodos para diferentes parámetros los hiperparámetros que menor ECM generen, \n",
    "    mediante Cross-Validation.\n",
    "    \n",
    "    input:\n",
    "        lista_parametros: lista de parámetros de regularización de los modelos que se van a usar para evaluar.\n",
    "        x: Variables explicativas.\n",
    "        y: Variable dependiente.\n",
    "        k: Cantidad de particiones de los datos.\n",
    "\n",
    "    output:\n",
    "        lista_todos: df que contiene la información de todos los modelos utilizados con las columnas\n",
    "               (modelo, particion, ecm, parámetro, accuracy, auc, fpr, tpr).\n",
    "        lista_promedios: df que hace el promedio por parámetro de los diferentes modelos, con las columnas \n",
    "                  (modelo, particion, ecm, parámetro, accuracy, auc, fpr, tpr)\n",
    "        lista_mejores: df que contiene la información de los mejores modelos elegido por ECM en los distintos modelos,\n",
    "                       con las columnas \n",
    "                  (modelo, particion, ecm, parámetro, accuracy, auc, fpr, tpr)\n",
    "    '''\n",
    "    \n",
    "    lista_todos = pd.DataFrame(columns=[\"modelo\", \"particion\", \"ecm\", \"parámetro\", \"auc\", \"accuracy\", \"fpr\", \"tpr\"])\n",
    "    lista_promedios = pd.DataFrame(columns=[\"modelo\", \"parámetro\", \"ecm\", \"auc\", \"accuracy\"])\n",
    "    lista_mejores = pd.DataFrame(columns=[\"modelo\", \"ecm\", \"parámetro\", \"auc\", \"accuracy\", \"fpr\", \"tpr\"])\n",
    "    \n",
    "    modelos = [\"Lineal\", \"KNN\", \"Logit\", \"CART\", \"SVM\", \"Bagging\", \"RandomForest\", \"Boosting\", \"Lasso\", \"Ridge\"]\n",
    "    for modelo in modelos:\n",
    "        todos, ecms_avg, ev_modelo = evalua_config(lista_parametros, x, y, k, modelo)\n",
    "        lista_todos = lista_todos.append(todos)\n",
    "        lista_promedios = lista_promedios.append(ecms_avg)\n",
    "        lista_mejores = lista_mejores.append(ev_modelo)\n",
    "        \n",
    "    return (lista_todos, lista_promedios, lista_mejores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47986b",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> (Rodrigo) En esta deberían definirse los distintos modelos y respectivos hiperparámetros que se van a probar en las funciones internas. Se puede usar un diccionario anidado como este:</span>\n",
    "\n",
    "```\n",
    "modelos = {\n",
    "    \"regresion_logistica\": { \n",
    "        \"modelo\": LogisticRegression, \n",
    "        \"hiperparametros\": [{ \"penalty\": \"l1\", \"C\"=0.1 }, { \"penalty\": \"l2\", \"C\"=0.001 }],\n",
    "    \"vecinos_cercanos\": { \n",
    "        \"modelo\": KNearestNeighbors, \n",
    "        \"hiperparametros\": [{\"n_neighbors\": n} for range(3,10)] \n",
    "    },\n",
    "}\n",
    "```\n",
    "<span style=\"color:red\">Lo que uso para definir los hiperparámetros de KNN es una técnica llamada \"definición de listas por comprensión\", lo pueden mirar en la tutorial 7. Luego pueden iterar sobre este diccionario de esta manera</span>\n",
    "\n",
    "```\n",
    "for nombre_modelo in modelos:\n",
    "    modelo = modelos[nombre_modelo][\"modelo\"] # esto puede valer, por ejemplo, LogisticRegression\n",
    "    configs = modelos[nombre_modelo][\"hiperparametros\"] # esta es la lista de configs. que voy a probar\n",
    "    \n",
    "    # agrego nombre_modelo a evalua_config como argumento \n",
    "    # porque puede resultar útil si se lo quiere agregar como columna de un dataframe\n",
    "    ... = evalua_config(nombre_modelo, modelo, configs, ...) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65c589",
   "metadata": {},
   "source": [
    "# Parte III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e032dad",
   "metadata": {},
   "source": [
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos todas las variables relacionadas a ingresos. \n",
    "#respondieron.drop(['ITF','DECIFR', 'RDECIFR', 'GDECCFR', 'ADECIFR', 'IPCF', 'DECCFR', 'RDECCFR','GDECCFR', 'ADECCFR', 'PONDIH'], axis=1, inplace=True)\n",
    "#norespondieron.drop(['ITF','DECIFR', 'RDECIFR', 'GDECCFR', 'ADECIFR', 'IPCF', 'DECCFR', 'RDECCFR','GDECCFR', 'ADECCFR', 'PONDIH'], axis=1, inplace=True)\n",
    "#'IDECCFR', 'PDECIFR', 'PDECCFR'\n",
    "#estas no las encontro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos de ambas bases las columnas de ingresos\n",
    "respondieron.drop([\"PP08D1\", \"PP08D4\", \"PP08F1\", \"PP08F2\", \"PP08J1\", \"PP08J2\", \"PP08J3\", \"P21\", \"TOT_P12\", \"P47T\",\\\n",
    "                  \"V2_M\", \"V3_M\", \"V4_M\", \"V5_M\", \"V8_M\", \"V9_M\", \"V10_M\", \"V11_M\", \"V12_M\", \"V18_M\", \"V19_AM\",\\\n",
    "                   \"V21_M\", \"T_VI\", \"ITF\", \"IPCF\", \"ingreso_necesario\", \"ad_equiv_hogar\", \"adulto_equiv\", \"IX_MAYEQ10\"], axis = 1, inplace = True)\n",
    "norespondieron.drop([\"PP08D1\", \"PP08D4\", \"PP08F1\", \"PP08F2\", \"PP08J1\", \"PP08J2\", \"PP08J3\", \"P21\", \"TOT_P12\", \"P47T\",\\\n",
    "                  \"V2_M\", \"V3_M\", \"V4_M\", \"V5_M\", \"V8_M\", \"V9_M\", \"V10_M\", \"V11_M\", \"V12_M\", \"V18_M\", \"V19_AM\",\\\n",
    "                    \"V21_M\", \"T_VI\", \"ITF\", \"IPCF\", \"ad_equiv_hogar\", \"adulto_equiv\", \"IX_MAYEQ10\"], axis = 1, inplace = True)\n",
    "# Nos dimos cuenta tarde que faltan cambiar algunas para que no aparezcan NaN y dropear las de deciles\n",
    "respondieron[\"CH14\"].fillna(99, inplace = True) #Muchos no respondieron entonces reemplazamos los missing por 99. \n",
    "norespondieron[\"CH14\"].fillna(99, inplace = True)\n",
    "respondieron.drop([\"CH15_COD\", \"CH16_COD\", \"PP03C\", \"PP03D\", \"CODUSU\"], axis = 1, inplace = True) # innecesarios (con muy pocas o ninguna observación) o de ingreso \n",
    "respondieron.drop([\"DECOCUR\", \"RDECOCUR\", \"GDECOCUR\", \"ADECOCUR\", \"PONDIIO\", \"DECIFR\", \"RDECIFR\", \"GDECIFR\",\\\n",
    "                   \"PONDII\", \"PONDIH\", \"PONDERA\", \"ADECIFR\", \"DECCFR\", \"RDECCFR\", \"GDECCFR\",\\\n",
    "                   \"ADECCFR\", \"DECINDR\", \"RDECINDR\", \"GDECINDR\", \"ADECINDR\", \"CH05\"], axis = 1, inplace = True) # todas deciles\n",
    "norespondieron.drop([\"CH15_COD\", \"CH16_COD\", \"PP03C\", \"PP03D\", \"CODUSU\"], axis = 1, inplace = True) # innecesarios (con muy pocas o ninguna observación) o de ingreso \n",
    "norespondieron.drop([\"DECOCUR\", \"RDECOCUR\", \"GDECOCUR\", \"ADECOCUR\", \"PONDIIO\", \"DECIFR\", \"RDECIFR\", \"GDECIFR\",\\\n",
    "                   \"PONDII\", \"PONDIH\", \"PONDERA\", \"ADECIFR\", \"DECCFR\", \"RDECCFR\", \"GDECCFR\",\\\n",
    "                   \"ADECCFR\", \"DECINDR\", \"RDECINDR\", \"GDECINDR\", \"ADECINDR\", \"CH05\"], axis = 1, inplace = True) # todas deciles\n",
    "respondieron.reset_index(inplace = True, drop = True)\n",
    "norespondieron.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una copia del dataframe para luego recuperar las columnas que no son categóricas\n",
    "respondieron_temp = respondieron.copy()\n",
    "norespondieron_temp = norespondieron.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herramienta para poder utilizar variables categóricas en los modelos.\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fbd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le aplicamos la herramienta al df\n",
    "respondieron = respondieron.apply(label_encoder.fit_transform)\n",
    "norespondieron = norespondieron.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a introducir las columnas no categóricas \n",
    "respondieron[[\"PP3E_TOT\", \"PP3F_TOT\", \"PP04B2\", \"PP04B3_MES\", \"PP04B3_ANO\", \"PP04B3_DIA\", \\\n",
    "              \"PP05B2_MES\", \"PP05B2_ANO\", \"PP05B2_DIA\", \"PP11B2_MES\", \"PP11B2_ANO\", \"PP11B2_DIA\",\n",
    "              \"IX_TOT\", \"IX_MEN10\"]] \\\n",
    "= respondieron_temp[[\"PP3E_TOT\", \"PP3F_TOT\", \"PP04B2\", \"PP04B3_MES\", \"PP04B3_ANO\", \"PP04B3_DIA\", \\\n",
    "                     \"PP05B2_MES\", \"PP05B2_ANO\", \"PP05B2_DIA\", \"PP11B2_MES\", \"PP11B2_ANO\", \"PP11B2_DIA\",\n",
    "                     \"IX_TOT\", \"IX_MEN10\"]] \n",
    "norespondieron[[\"PP3E_TOT\", \"PP3F_TOT\", \"PP04B2\", \"PP04B3_MES\", \"PP04B3_ANO\", \"PP04B3_DIA\", \\\n",
    "              \"PP05B2_MES\", \"PP05B2_ANO\", \"PP05B2_DIA\", \"PP11B2_MES\", \"PP11B2_ANO\", \"PP11B2_DIA\",\"IX_TOT\", \"IX_MEN10\"]] \\\n",
    "= norespondieron_temp[[\"PP3E_TOT\", \"PP3F_TOT\", \"PP04B2\", \"PP04B3_MES\", \"PP04B3_ANO\", \"PP04B3_DIA\", \\\n",
    "                     \"PP05B2_MES\", \"PP05B2_ANO\", \"PP05B2_DIA\", \"PP11B2_MES\", \"PP11B2_ANO\", \"PP11B2_DIA\",\n",
    "                      \"IX_TOT\", \"IX_MEN10\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos la columna de 1 \n",
    "respondieronx = respondieron.iloc[:, :-1]\n",
    "respondieronx[\"inter\"] = 1\n",
    "norespondieron[\"inter\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8fd07",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bc0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corremos evalua_multiples_metodos con el hiperparámetro 2\n",
    "lista = [2]\n",
    "todo, promedio, mejor = evalua_multiples_metodos(lista,respondieronx,respondieron[\"pobre\"],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88dea64",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99ed63",
   "metadata": {},
   "source": [
    "λ lo elegiríamos por cross validation ya que queremos minimizar el error de pronostico por fuera de la muestra. Por lo tanto, debe estimarse el modelo para muchos valores de λ alternativos y calcular el error de pronóstico por cross validation. Para esto\n",
    "primero hay qye partir los datos al azar en K partes, luego ajustar el modelo dejando afuera una de las particiones y, por último, Computar el error de predicción para los datos no utilizados. Esto debe repetirse para k = 1,...,K. \n",
    "Una vez hecho esto, vamos a elegir el valor de λ que genere la mejor capacidad predictiva, es decir, el que minimiza el error de pronóstico fuera de la muestra computado por cross validation. Este es el sentido en el cual el modelo esta aprendiendo, dado  que estamos haciendo que los datos elijan el λ óptimo.\n",
    "\n",
    "\n",
    "Para la eleccion no debe usarse el conjunto de prueba dado que no podríamos comparar el desempeño con otros modelos dado que todos los modelos se estiman con los datos de entrenamiento y luego se evalúan con los datos de test. Por lo tanto, si en un modelo a λ lo computamos usando los datos de test, deja de ser comparable con el resto de los modelos, ya que tendría una ventaja por sobre todos los demás. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853eab5",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "(Rodrigo) Lo que escribieron es correcto, pero dejo la siguiente explicación que escribí para otro grupo para asegurarme que el concepto queda claro:<br><br>\n",
    "Es importante que, al elegir un hiperparámetro de un modelo, todo el proceso de CV ocurra dentro del conjunto de entrenamiento.\n",
    "Supongamos que tenemos 100 observaciones, por poner un número redondo, y separamos 80 para training y 20 para testing. Queremos usar las 80 observaciones para elegir y ajustar el mejor modelo posible (esto incluye elegir los mejor hiperparámetros), y las 20 restantes para evaluar qué tan bien predice ese modelo que generamos.</span>\n",
    "<span style=\"color:red\"> <br>\n",
    "Ahora imaginemos que tenemos una familia de modelos, como ocurre en regresión logística (donde cada miembro de la familia corresponde a un conjunto distinto de hiperparámetros). Entonces para lo que usamos k-fold CV es para elegir al mejor miembro de esta familia, es decir al mejor conjunto de hiperparámetros. Para eso, con cada configuración de hiperparámetros (supongamos que k = 5), separamos 16 observaciones y ajustamos el modelo en las 64 restantes, y así vamos cambiando las 16 observaciones que dejamos afuera, y en cada caso obtenemos un modelo ajustado distinto. (Estas 16 observaciones se las suele denominar de validación para distinguirlas de las 20 de testing, que no deben participar de este proceso para nada). Luego promediamos los ECM obtenidos para cada partición para obtener un mejor estimado. En base a este estimado elegimos el hiperparámetro.\n",
    "Ahora, una vez que elegimos el hiperparámetro, es mejor ajustar el modelo de nuevo pero ahora sobre las 80 observaciones, y usar los 20 restantes (las de testing) para reportar las métricas.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6b5ba",
   "metadata": {},
   "source": [
    "## 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d89dba",
   "metadata": {},
   "source": [
    "El problema de usar un K muy pequeño es que a pesar de que maximiza los datos para estimar, es sensible a los valores particulares para la evaluación. Por lo que el error de pronostico depende mucho de lo que pase con los pocos datos de test.\n",
    "Por otro lado, el problema de usar un muy K grande es que a pesar de que maximiza los datos para evaluar, el modelo es estimado menos precisamente dado que se usan menos datos de entrenamiento.\n",
    "Por último, cuando K = N se va dejando de lado una observación por vez. Así, se estima el modelo n veces con n − 1 datos (‘leave one out’)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c169c4b",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "(Rodrigo) La afirmación de que para K grande se usan menos datos para entrenar no es correcta, de hecho lo contrario lo es. Ejemplo: si K=5, se entrena con el 80% de las observaciones cada vez; si K=10, se usa el 90%. El problema de usar un K grande viene dado por el número de veces que se tiene que entrenar el modelo, lo cual puede resultar muy costoso computacionalmente sin un beneficio asociado que lo justifique. Como bien dicen, hacer K=N implica entrenar el modelo N veces con N-1 datos. Si la base es muy grande, esto puede ser muy costoso de hacer computacionalmente, sumado a que no hay mucha ganancia ya que ya se obtendría una performance similar entrenando con el 80 ó 90% de los datos. Puede tener sentido hacer K=N sentido si la base es muy chica y queremos quitar tan pocas observaciones como podamos a la hora de entrenar. De lo contrario, un K del orden de 5 ó 10 es en general deseable.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32242c91",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564917f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la lista de parámetros a evaluar en Lasso y Ridge.\n",
    "lista = 10**np.linspace(-5,5,11)\n",
    "todos_l, promedio_l, mejor_l = evalua_config(lista, respondieronx,respondieron[\"pobre\"],10,\"Lasso\")\n",
    "todos_r, promedio_r, mejor_r = evalua_config(lista, respondieronx,respondieron[\"pobre\"],10,\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325885b1",
   "metadata": {},
   "source": [
    "El λ elegido en regresión logísitica con Ridge y Lasso es 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las variables en las cuales almaceno su ecm por parámetro, para las diferentes particiones\n",
    "for i, x in zip(lista, range(1,12,1)):\n",
    "     locals()[\"l_\"+str(x)] = todos_l[todos_l[\"parámetro\"]==i].ecm\n",
    "for i, x in zip(lista, range(1,12,1)):\n",
    "     locals()[\"r_\"+str(x)] = todos_r[todos_r[\"parámetro\"]==i].ecm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d57317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una variable con todas las variables con los ecm por parámetro para hacer el boxplot\n",
    "data_l = (l_1,l_2,l_3,l_4,l_5,l_6,l_7,l_8,l_9,l_10,l_11)\n",
    "data_r = (r_1,r_2,r_3,r_4,r_5,r_6,r_7,r_8,r_9,r_10,r_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot para Lasso\n",
    "fig, ax = plt.subplots(figsize =(15, 7))\n",
    "ax.xaxis.set(ticklabels=[0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000])\n",
    "ax.set(title=\"ECM por parámetro para Lasso\" , ylabel= \"ECM\", xlabel= \"Parámetro\")\n",
    "ax.boxplot(data_l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7554807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot para Ridge\n",
    "fig, ax = plt.subplots(figsize =(15, 7))\n",
    "ax.xaxis.set(ticklabels=[0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000])\n",
    "ax.set(title=\"ECM por parámetro para Ridge\" , ylabel= \"ECM\", xlabel= \"Parámetro\")\n",
    "ax.boxplot(data_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos el df coe_cvs por parámetro\n",
    "coeficientes_1 = coe_cvs[coe_cvs[\"parámetro\"]== 0.00001][\"coeficientes\"]\n",
    "coeficientes_1.reset_index(inplace = True, drop = True)\n",
    "coeficientes_2 = coe_cvs[coe_cvs[\"parámetro\"]== 0.0001][\"coeficientes\"]\n",
    "coeficientes_2.reset_index(inplace = True, drop = True)\n",
    "coeficientes_3 = coe_cvs[coe_cvs[\"parámetro\"]== 0.001][\"coeficientes\"]\n",
    "coeficientes_3.reset_index(inplace = True, drop = True)\n",
    "coeficientes_4 = coe_cvs[coe_cvs[\"parámetro\"]== 0.01][\"coeficientes\"]\n",
    "coeficientes_4.reset_index(inplace = True, drop = True)\n",
    "coeficientes_5 = coe_cvs[coe_cvs[\"parámetro\"]== 0.1][\"coeficientes\"]\n",
    "coeficientes_5.reset_index(inplace = True, drop = True)\n",
    "coeficientes_6 = coe_cvs[coe_cvs[\"parámetro\"]== 1.0][\"coeficientes\"]\n",
    "coeficientes_6.reset_index(inplace = True, drop = True)\n",
    "coeficientes_7 = coe_cvs[coe_cvs[\"parámetro\"]== 10.0][\"coeficientes\"]\n",
    "coeficientes_7.reset_index(inplace = True, drop = True)\n",
    "coeficientes_8 = coe_cvs[coe_cvs[\"parámetro\"]== 100.0][\"coeficientes\"]\n",
    "coeficientes_8.reset_index(inplace = True, drop = True)\n",
    "coeficientes_9 = coe_cvs[coe_cvs[\"parámetro\"]== 1000.0][\"coeficientes\"]\n",
    "coeficientes_9.reset_index(inplace = True, drop = True)\n",
    "coeficientes_10 = coe_cvs[coe_cvs[\"parámetro\"]== 10000.0][\"coeficientes\"]\n",
    "coeficientes_10.reset_index(inplace = True, drop = True)\n",
    "coeficientes_11 = coe_cvs[coe_cvs[\"parámetro\"]== 100000.0][\"coeficientes\"]\n",
    "coeficientes_11.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30dfcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos variables que contengan la cantidad de ceros que tienen las diferentes particiones para poder hacer el boxplot.\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_1[x]==0)\n",
    "data_1 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_2[x]==0)\n",
    "data_2 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_3[x]==0)\n",
    "data_3 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_4[x]==0)\n",
    "data_4 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_5[x]==0)\n",
    "data_5 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_6[x]==0)\n",
    "data_6 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_7[x]==0)\n",
    "data_7 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_8[x]==0)\n",
    "data_8 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_9[x]==0)\n",
    "data_9 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_10[x]==0)\n",
    "data_10 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)\n",
    "for x in range(0,10,1):\n",
    "    locals()[\"ceros_\"+str(x)] = np.count_nonzero(coeficientes_11[x]==0)\n",
    "data_11 = (ceros_0, ceros_1, ceros_2, ceros_3, ceros_4, ceros_5, ceros_6, ceros_7, ceros_8, ceros_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las agrupo en una variable para poder hacer el boxplot\n",
    "data = (data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,data_10,data_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de variables eliminadas por parámetro para Lasso\n",
    "fig, ax = plt.subplots(figsize =(15, 7))\n",
    "ax.xaxis.set(ticklabels=[0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000])\n",
    "ax.set(title=\"Variables eliminadas por parámetro en Lasso\" , ylabel= \"Cant var eliminadas\", xlabel= \"Parámetro\")\n",
    "ax.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b011347",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> (Rodrigo) Excelente, este es el comportamiento esperado. En el límite cuando lambda tiende a cero, es equivalente a entrenar mínimos cuadrados ordinarios (ya que el término de Lasso no tiene peso). En el otro extremo, sólo el término de penalización de Lasso tiene preponderancia en la función de costo del modelo, por lo tanto lo único que \"quiere\" el modelo es hacer los coeficientes iguales a cero, sin importar la bondad de la predicción.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3021b139",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8f76f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# El mejor modelo.\n",
    "mejor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d13d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos para poder aplicar la función.\n",
    "X_train, X_test, y_train, y_test = train_test_split(respondieronx,respondieron[\"pobre\"],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e8d8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Corremos el mejor modelo\n",
    "evalua_metodo(X_train, X_test, y_train, y_test, \"Lasso\", mejor_l[\"parámetro\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da4891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Estas son las variables descartadas\n",
    "coef2[coef2[0] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524b9ba",
   "metadata": {},
   "source": [
    "Las variables descartadas son las que hubieramos esperado, ya que creemos que al ver el diseño de registro de la base hogar parecían ser irrelevantes para explicar la tasa de pobreza. Por ejemplo el año de relevamiento (ANO4), la ventana de observación (TRIMESTRE) y el codigo de region (REGION) no parecen variables que tengan una relacion significativa con la tasa de pobreza.\n",
    "Con respecto a lo respondido en el inciso 1 de la Parte 1, ninguna de las variables que creíamos a priori relevantes para predecir pobreza fueron eliminidas, por lo que efectivamente presentan un poder explicativo significativo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce392f28",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos estos dos modelos con mismo parámetro\n",
    "promedio_l[promedio_l[\"parámetro\"] == 100].ecm.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3be0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparamos estos dos modelos con mismo parámetro\n",
    "promedio_r[promedio_r[\"parámetro\"] == 100].ecm.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb7e48",
   "metadata": {},
   "source": [
    "Por lo tanto, Lasso funcionó mejor ya que se obtiene un error cuadratico medio menor que en el caso de Ridge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360e88b",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúamos todos los modelos dentro de multiples modelos para poder definir cual es el que mejor predice.\n",
    "todo2, promedio2, mejor2 = evalua_multiples_metodos(lista, respondieronx, respondieron[\"pobre\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c7393",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mejor2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579d61e",
   "metadata": {},
   "source": [
    "El método que predice mejor es Boosting con el hiperparámetro 0.00001, dado que presenta el mínimo error cuadrático medio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f254ea",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ult = GradientBoostingClassifier(learning_rate=1.0, ccp_alpha = 0.00001)\n",
    "# Ajustamos el modelo        \n",
    "ult = ult.fit(X_train, y_train)     \n",
    "    \n",
    "# Luego predecimos y con las X de evaluación.\n",
    "y_pred = ult.predict(X_test)\n",
    "\n",
    "# Probabilidad de que Y tome valor 1 segun el valor de X \n",
    "y_pred_proba = ult.predict_proba(X_test)[:,1]\n",
    "\n",
    "#Valores de Accuracy\n",
    "accuracy_pob = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Valores de AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "#Curva ROC\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='Reg_log')\n",
    "def ROC(roc):\n",
    "        display.plot()  \n",
    "        plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "        plt.show()\n",
    "ROC(display)\n",
    "\n",
    "# Error cuadrático medio\n",
    "        \n",
    "ecm = mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a424e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nr = ult.predict(norespondieron)\n",
    "y_pred_nr.sum()\n",
    "y_pred_nr.sum()/816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b26cbb",
   "metadata": {},
   "source": [
    "El 43,9% de los hogares son pobres en ests submuestra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
